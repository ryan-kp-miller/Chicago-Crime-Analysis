{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-candidate"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.6 64-bit",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "1063ac4b9ce877ea2f7b2876ccc72361f52441c9fec357e43a850c5500cc029e"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Data Preprocessing\n",
    "As of 3/10/2020, the [dataset](https://data.cityofchicago.org/Public-Safety/Crimes-2001-to-present/ijzp-q8t2) provided by the city of Chicago on crime (excluding murders) contains over 7 millions rows and 22 columns. This [dataset](https://data.cityofchicago.org/Public-Safety/Homicides/k9xv-yxzs) contained the homicides, about 10,000, from the last 20 years. To facilitate early exploration of the data and focus on more recent, relevant trends, I removed crimes from before 2010, unneeded columns, and rows with nulls. The reduced dataset contained just under 3 million rows of crimes  \n",
    "  \n",
    "After reducing the size of the dataset, I cleaned up the text columns by manually matching values of each column with a smaller subset of categories in excel, mapped the Community Area ID's to their name and group (e.g. Community Area 8 maps to Near North Side and Central) based on [this](https://en.wikipedia.org/wiki/Community_areas_in_Chicago) Wikipedia page, and added some categorical columns based on the date of the crime.  \n",
    "\n",
    "Also added in the Community Area population sizes from the [2010 Census](https://www.chicago.gov/content/dam/city/depts/zlup/Zoning_Main_Page/Publications/Census_2010_Community_Area_Profiles/Census_2010_and_2000_CA_Populations.pdf) to allow for an approximated Crimes/Homicides per Capita calculation. Unfortunately, this data isn't provided year over year and as of 3/30/2020, the 2020 Census isn't available, which is why I needed to use 2010 population sizes."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Dataset Description:\n",
    "These are the original column descriptions from the City of Chicago \n",
    "[website](https://data.cityofchicago.org/Public-Safety/Crimes-2001-to-present/ijzp-q8t2)  "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "| Column Name  | Column Description |  \n",
    "| :-:    | :-: |  \n",
    "| ID           | Unique identifier for the record |\n",
    "| Case Number  | The Chicago Police Department Records Division Number |\n",
    "| Date         | Date when the incident occurred (sometimes an estimate) |\n",
    "| Block        | The partially redacted address where the incident occurred, placing it on the same block as the actual address |\n",
    "| IUCR         | Illinois Uniform Crime Reporting code |\n",
    "| Primary Type | The primary description of the IUCR code |\n",
    "| Description  | The secondary description of the IUCR code, a subcategory of the primary description |\n",
    "| Location Description | Description of the location where the incident occurred |\n",
    "| Arrest | Indicates whether an arrest was made |\n",
    "| Domestic | Indicates whether the incident was domestic-related as defined by the Illinois Domestic Violence act |\n",
    "| Beat | Indicates the beat where the incident occurred. A beat is the smallest police geographic area. 3 to 5 beats make up a police sector, and 3 sectors make up a police district |\n",
    "| District | Indicates the police district where the incident occurred |\n",
    "| Ward | The ward (City Council district) where the incident occurred |\n",
    "| Community Area | Indicates the community area where the incident occurred (Chicago has 77 community areas) |\n",
    "| FBI Code | Indicates the crime classification as outlined in the FBI's National Incident-Based Reporting System (NIBRS) |\n",
    "| X Coordinate | The x coordinate of the location where the incident occurred in State Plane Illinois East NAD 1983 projection. This location is shifted from the actual location for partial redaction but falls on the same block |\n",
    "| Y Coordinate | The y coordinate of the location where the incident occurred in State Plane Illinois East NAD 1983 projection. This location is shifted from the actual location for partial redaction but falls on the same block |\n",
    "| Year | The year the incident occurred |\n",
    "| Updated On | Date and time the record was last updated |\n",
    "| Latitude | The latitude of the location where the incident occurred. This location is shifted from the actual location for partial redaction but falls on the same block |\n",
    "| Longitude | The longitude of the location where the incident occurred. This location is shifted from the actual location for partial redaction but falls on the same block |\n",
    "| Location | The location where the incident occurred in a format that allows for creation of maps and other geographic operations on this data portal. This location is shifted from the actual location for partial redaction but falls on the same block |"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "#Setting the required parameters to start up PySpark\n",
    "driver_memory = '6g'\n",
    "num_executors = 2\n",
    "executor_memory = '1g'\n",
    "pyspark_submit_args = ' --driver-memory ' + driver_memory + ' pyspark-shell'\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"] = pyspark_submit_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
   ]
  },
  {
   "source": [
    "### Defining the Dataset Schemas\n",
    "\n",
    "The schema for both the homicides and general crimes data is based on the metadata shown [here](https://data.cityofchicago.org/Public-Safety/Homicides/k9xv-yxzs)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_schema = StructType([\n",
    "    StructField('id', IntegerType(), False),\n",
    "    StructField('case_number', StringType(), True),\n",
    "    StructField('date', StringType(), True),\n",
    "    StructField('block', StringType(), True),\n",
    "    StructField('iucr', StringType(), True),\n",
    "    StructField('primary_type', StringType(), True),\n",
    "    StructField('description', StringType(), True),\n",
    "    StructField('location_description', StringType(), True),\n",
    "    StructField('arrest', BooleanType(), True),\n",
    "    StructField('domestic', BooleanType(), True),\n",
    "    StructField('beat', StringType(), True),\n",
    "    StructField('district', StringType(), True),\n",
    "    StructField('ward', IntegerType(), True),\n",
    "    StructField('community_area', StringType(), True),\n",
    "    StructField('fbi_code', StringType(), True),\n",
    "    StructField('x_coord', IntegerType(), True),\n",
    "    StructField('y_coord', IntegerType(), True),\n",
    "    StructField('year', IntegerType(), True),\n",
    "    StructField('updated_on', DateType(), True),\n",
    "    StructField('latitude', DoubleType(), True),\n",
    "    StructField('longitude', DoubleType(), True),\n",
    "    StructField('location', StringType(), True),\n",
    "])\n",
    "\n",
    "ca_schema = StructType([\n",
    "    StructField('community_area', IntegerType(), False),\n",
    "    StructField('name', StringType(), False),\n",
    "    StructField('region', StringType(), False),\n",
    "    StructField('pop_2010', IntegerType(), False),\n",
    "])\n",
    "\n",
    "loc_schema = StructType([\n",
    "    StructField('location_description', StringType(), False),\n",
    "    StructField('location_formatted', StringType(), False),\n",
    "])"
   ]
  },
  {
   "source": [
    "### Reading in the Datasets"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "There were 7,233,087 crimes in Chicago from 2001 to the present.\n"
     ]
    }
   ],
   "source": [
    "# read in the homicides and non-homicide crimes and append the datasets together\n",
    "homicides_df = spark.read.csv('./Data/Homicides.csv', schema=crime_schema, header=True)\n",
    "gen_crimes_df = spark.read.csv('./Data/Crimes_-_2001_to_Present.csv', schema=crime_schema, header=True)\n",
    "crime_df = homicides_df.union(gen_crimes_df)\n",
    "# crime_df = spark.read.csv('./Data/Homicides.csv', schema=crime_schema, header=True) # for testing purposes\n",
    "\n",
    "# read in the formatted location descriptions and the community area attributes\n",
    "location_desc_df = spark.read.csv(\"./Data/Location.csv\", schema=loc_schema, header=True)\n",
    "comm_area_df = spark.read.csv(\"./Data/Community_Areas.csv\", schema=ca_schema, header=True)\n",
    "\n",
    "print(\"There were {:,d} crimes in Chicago from 2001 to the present.\".format(crime_df.count()))"
   ]
  },
  {
   "source": [
    "### Using SQL to Create the Final Dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting `date` from String to Timestamp\n",
    "crime_df = crime_df.withColumn(\"date\", F.to_timestamp(\"date\", \"MM/dd/yyyy hh:mm:ss a\"))\n",
    "crime_df = crime_df.withColumn(\"week_day_num\", F.dayofweek(crime_df.date))\n",
    "\n",
    "crime_df.createOrReplaceTempView(\"crime\")\n",
    "location_desc_df.createOrReplaceTempView(\"location\")\n",
    "comm_area_df.createOrReplaceTempView(\"comm_area\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT crime.date AS Date\n",
    "    ,CASE WHEN (crime.primary_type = 'NON - CRIMINAL') OR (crime.primary_type = 'NON-CRIMINAL (SUBJECT SPECIFIED)') \n",
    "        THEN 'NON-CRIMINAL' ELSE crime.primary_type END AS `Primary Type`\n",
    "    ,CAST(crime.arrest as INTEGER) AS Arrest\n",
    "    ,crime.domestic AS Domestic\n",
    "    ,YEAR(crime.date) AS Year\n",
    "    ,crime.latitude AS Latitude\n",
    "    ,crime.longitude AS Longitude\n",
    "    ,location.location_formatted AS `Location Description`\n",
    "    ,comm_area.name AS `Community Area`\n",
    "    ,comm_area.region AS Region\n",
    "    ,comm_area.pop_2010 AS `2010 Population`\n",
    "    ,MONTH(crime.date) AS Month\n",
    "    ,CASE WHEN HOUR(crime.date) BETWEEN  5 AND 12 THEN 'Morning'\n",
    "          WHEN HOUR(crime.date) BETWEEN 12 AND 17 THEN 'Afternoon'\n",
    "          WHEN HOUR(crime.date) BETWEEN 17 AND 20 THEN 'Evening'\n",
    "          WHEN HOUR(crime.date) >= 20 OR HOUR(crime.date) < 5 THEN 'Night'\n",
    "     END AS `Time of Day`\n",
    "\n",
    "    ,CASE WHEN crime.week_day_num = 1 THEN 'Sunday'\n",
    "          WHEN crime.week_day_num = 2 THEN 'Monday'\n",
    "          WHEN crime.week_day_num = 3 THEN 'Tuesday'\n",
    "          WHEN crime.week_day_num = 4 THEN 'Wednesday'\n",
    "          WHEN crime.week_day_num = 5 THEN 'Thursday'\n",
    "          WHEN crime.week_day_num = 6 THEN 'Friday'\n",
    "          WHEN crime.week_day_num = 7 THEN 'Saturday'\n",
    "     END AS `Day of Week`\n",
    "\n",
    "    ,CASE WHEN MONTH(crime.date) IN ( 3,  4,  5) THEN 'Spring'\n",
    "          WHEN MONTH(crime.date) IN ( 6,  7,  8) THEN 'Summer'\n",
    "          WHEN MONTH(crime.date) IN ( 9, 10, 11) THEN 'Fall'\n",
    "          WHEN MONTH(crime.date) IN (12,  1,  2) THEN 'Winter'\n",
    "     END AS Season\n",
    "\n",
    "FROM crime\n",
    "    INNER JOIN location ON location.location_description = crime.location_description\n",
    "    INNER JOIN comm_area ON comm_area.community_area = crime.community_area\n",
    "\n",
    "WHERE YEAR(crime.date) BETWEEN 2010 AND 2019\n",
    "    AND crime.date IS NOT NULL\n",
    "    AND crime.latitude IS NOT NULL\n",
    "    AND crime.arrest IS NOT NULL\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of crimes in the final dataset: 2,949,016\n",
      "56.9 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1 -r1 # to let you know how long it takes this cell to run\n",
    "\n",
    "crime_sql_df = spark.sql(query)\n",
    "\n",
    "print(\"Number of crimes in the final dataset: {:,d}\".format(crime_sql_df.count()))\n",
    "\n",
    "# convert the crime type to title case for nicer looking values\n",
    "crime_sql_df = crime_sql_df.withColumn('Primary Type', F.initcap(crime_sql_df['Primary Type']))\n",
    "\n",
    "# using collect() and then converting to pandas df because it's faster\n",
    "crime_dict = crime_sql_df.collect()\n",
    "crime_pd_df = pd.DataFrame(crime_dict, columns=crime_sql_df.columns)\n",
    "crime_pd_df.to_csv(\"./Data/crimes_cleaned.csv\", index=False)"
   ]
  }
 ]
}